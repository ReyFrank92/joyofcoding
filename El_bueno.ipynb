{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "El bueno.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6B74SoGoVRGZZ0Yi+233F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReyFrank92/joyofcoding/blob/main/El_bueno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O45KZTy37Ea",
        "outputId": "33e8284e-36f9-4805-c194-a21fc83af308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "#Install TensorFlow\n",
        "!pip install -q tensorflow-gpu==2.9.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, SimpleRNN, Dense,  GRU, LSTM, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "wi-7f41g39bI"
      },
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "data_to_load = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Rfh9c9uK3_I3",
        "outputId": "ee7fc838-cacd-42fa-cf15-9958b5836514"
      },
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4209d26e-1037-4fa7-865c-a878df04688a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4209d26e-1037-4fa7-865c-a878df04688a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Resumen_petroleo.csv to Resumen_petroleo (9).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Resumen_petroleo.csv', index_col='Fecha', parse_dates=True)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eY3LUkW4Al3",
        "outputId": "c4777133-b1e9-4fd1-f1bf-4f41a36b9910"
      },
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(318, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from typing import ValuesView"
      ],
      "metadata": {
        "id": "65YQc42d4Bhm"
      },
      "execution_count": 479,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N = number of samples\n",
        "# T = sequence length\n",
        "# D = number of input features\n",
        "# M = number of hideen units \n",
        "# K = number of output units"
      ],
      "metadata": {
        "id": "-RE4X1UA4PK8"
      },
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Log_MM'] = np.log(df['MM'])\n",
        "df['Log_WTI'] = np.log(df['WTI'])\n",
        "df['Log_Brent'] = np.log(df['BRENT'])\n",
        "df['Log_DJI'] = np.log(df['DJI'])\n",
        "df['Log_XAU'] = np.log(df['XAU'])\n",
        "df['Log_Oil C1'] = np.log(df['Oil C1'])"
      ],
      "metadata": {
        "id": "ykkUKW7w4Qdl"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "itr6l2qQ4xzX",
        "outputId": "c5870e0f-1446-4040-d03c-ba9dcfe63d95"
      },
      "execution_count": 482,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                MM     WTI   BRENT       DJI      XAU  Oil C1    Log_MM  \\\n",
              "Fecha                                                                     \n",
              "1996-01-31   15.12   17.76   16.63   5395.30   406.45   17.74  2.716018   \n",
              "1996-02-29   16.82   19.59   18.80   5485.62   399.75   19.54  2.822569   \n",
              "1996-03-29   18.35   21.43   20.33   5587.14   395.45   21.47  2.909630   \n",
              "1996-04-30   17.61   20.95   19.50   5569.07   391.65   21.20  2.868467   \n",
              "1996-05-31   16.48   19.77   18.10   5643.17   391.00   19.76  2.802148   \n",
              "...            ...     ...     ...       ...      ...     ...       ...   \n",
              "2013-05-31   95.58   91.93  100.43  15115.57  1386.90   91.97  4.559964   \n",
              "2013-06-28   96.30   96.36  102.49  14909.60  1234.25   96.56  4.567468   \n",
              "2013-07-31  100.87  105.10  107.89  15499.54  1323.10  105.03  4.613833   \n",
              "2013-08-30  102.98  107.98  115.97  14810.31  1396.40  107.65  4.634535   \n",
              "2013-09-30   97.94  102.36  107.85  15129.67  1327.55  102.33  4.584355   \n",
              "\n",
              "             Log_WTI  Log_Brent   Log_DJI   Log_XAU  Log_Oil C1  DiffLogMM  \\\n",
              "Fecha                                                                        \n",
              "1996-01-31  2.876949   2.811208  8.593283  6.007461    2.875822        NaN   \n",
              "1996-02-29  2.975019   2.933857  8.609885  5.990839    2.972464   0.106550   \n",
              "1996-03-29  3.064792   3.012098  8.628223  5.980024    3.066657   0.087061   \n",
              "1996-04-30  3.042139   2.970414  8.624983  5.970369    3.054001  -0.041163   \n",
              "1996-05-31  2.984166   2.895912  8.638201  5.968708    2.983660  -0.066319   \n",
              "...              ...        ...       ...       ...         ...        ...   \n",
              "2013-05-31  4.521027   4.609461  9.623481  7.234826    4.521462  -0.036771   \n",
              "2013-06-28  4.568091   4.629765  9.609761  7.118219    4.570165   0.007505   \n",
              "2013-07-31  4.654912   4.681112  9.648566  7.187733    4.654246   0.046364   \n",
              "2013-08-30  4.681946   4.753332  9.603079  7.241653    4.678885   0.020702   \n",
              "2013-09-30  4.628496   4.680741  9.624413  7.191090    4.628203  -0.050180   \n",
              "\n",
              "            DiffLogWTI  DiffLogBRENT  DiffLogDJI  DiffLogXAU  DiffLogOil C1  \n",
              "Fecha                                                                        \n",
              "1996-01-31         NaN           NaN         NaN         NaN            NaN  \n",
              "1996-02-29    0.098070      0.122649    0.016602   -0.016622       0.096642  \n",
              "1996-03-29    0.089773      0.078241    0.018337   -0.010815       0.094193  \n",
              "1996-04-30   -0.022653     -0.041683   -0.003239   -0.009656      -0.012655  \n",
              "1996-05-31   -0.057973     -0.074503    0.013218   -0.001661      -0.070341  \n",
              "...                ...           ...         ...         ...            ...  \n",
              "2013-05-31   -0.013935     -0.010893    0.018413   -0.063010      -0.016071  \n",
              "2013-06-28    0.047064      0.020304   -0.013720   -0.116608       0.048702  \n",
              "2013-07-31    0.086821      0.051347    0.038805    0.069514       0.084081  \n",
              "2013-08-30    0.027034      0.072219   -0.045487    0.053920       0.024639  \n",
              "2013-09-30   -0.053450     -0.072590    0.021334   -0.050562      -0.050682  \n",
              "\n",
              "[213 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60015ce5-f124-45f8-b4a6-8763f91b8343\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MM</th>\n",
              "      <th>WTI</th>\n",
              "      <th>BRENT</th>\n",
              "      <th>DJI</th>\n",
              "      <th>XAU</th>\n",
              "      <th>Oil C1</th>\n",
              "      <th>Log_MM</th>\n",
              "      <th>Log_WTI</th>\n",
              "      <th>Log_Brent</th>\n",
              "      <th>Log_DJI</th>\n",
              "      <th>Log_XAU</th>\n",
              "      <th>Log_Oil C1</th>\n",
              "      <th>DiffLogMM</th>\n",
              "      <th>DiffLogWTI</th>\n",
              "      <th>DiffLogBRENT</th>\n",
              "      <th>DiffLogDJI</th>\n",
              "      <th>DiffLogXAU</th>\n",
              "      <th>DiffLogOil C1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fecha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1996-01-31</th>\n",
              "      <td>15.12</td>\n",
              "      <td>17.76</td>\n",
              "      <td>16.63</td>\n",
              "      <td>5395.30</td>\n",
              "      <td>406.45</td>\n",
              "      <td>17.74</td>\n",
              "      <td>2.716018</td>\n",
              "      <td>2.876949</td>\n",
              "      <td>2.811208</td>\n",
              "      <td>8.593283</td>\n",
              "      <td>6.007461</td>\n",
              "      <td>2.875822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-02-29</th>\n",
              "      <td>16.82</td>\n",
              "      <td>19.59</td>\n",
              "      <td>18.80</td>\n",
              "      <td>5485.62</td>\n",
              "      <td>399.75</td>\n",
              "      <td>19.54</td>\n",
              "      <td>2.822569</td>\n",
              "      <td>2.975019</td>\n",
              "      <td>2.933857</td>\n",
              "      <td>8.609885</td>\n",
              "      <td>5.990839</td>\n",
              "      <td>2.972464</td>\n",
              "      <td>0.106550</td>\n",
              "      <td>0.098070</td>\n",
              "      <td>0.122649</td>\n",
              "      <td>0.016602</td>\n",
              "      <td>-0.016622</td>\n",
              "      <td>0.096642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-03-29</th>\n",
              "      <td>18.35</td>\n",
              "      <td>21.43</td>\n",
              "      <td>20.33</td>\n",
              "      <td>5587.14</td>\n",
              "      <td>395.45</td>\n",
              "      <td>21.47</td>\n",
              "      <td>2.909630</td>\n",
              "      <td>3.064792</td>\n",
              "      <td>3.012098</td>\n",
              "      <td>8.628223</td>\n",
              "      <td>5.980024</td>\n",
              "      <td>3.066657</td>\n",
              "      <td>0.087061</td>\n",
              "      <td>0.089773</td>\n",
              "      <td>0.078241</td>\n",
              "      <td>0.018337</td>\n",
              "      <td>-0.010815</td>\n",
              "      <td>0.094193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-04-30</th>\n",
              "      <td>17.61</td>\n",
              "      <td>20.95</td>\n",
              "      <td>19.50</td>\n",
              "      <td>5569.07</td>\n",
              "      <td>391.65</td>\n",
              "      <td>21.20</td>\n",
              "      <td>2.868467</td>\n",
              "      <td>3.042139</td>\n",
              "      <td>2.970414</td>\n",
              "      <td>8.624983</td>\n",
              "      <td>5.970369</td>\n",
              "      <td>3.054001</td>\n",
              "      <td>-0.041163</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.041683</td>\n",
              "      <td>-0.003239</td>\n",
              "      <td>-0.009656</td>\n",
              "      <td>-0.012655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-05-31</th>\n",
              "      <td>16.48</td>\n",
              "      <td>19.77</td>\n",
              "      <td>18.10</td>\n",
              "      <td>5643.17</td>\n",
              "      <td>391.00</td>\n",
              "      <td>19.76</td>\n",
              "      <td>2.802148</td>\n",
              "      <td>2.984166</td>\n",
              "      <td>2.895912</td>\n",
              "      <td>8.638201</td>\n",
              "      <td>5.968708</td>\n",
              "      <td>2.983660</td>\n",
              "      <td>-0.066319</td>\n",
              "      <td>-0.057973</td>\n",
              "      <td>-0.074503</td>\n",
              "      <td>0.013218</td>\n",
              "      <td>-0.001661</td>\n",
              "      <td>-0.070341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-05-31</th>\n",
              "      <td>95.58</td>\n",
              "      <td>91.93</td>\n",
              "      <td>100.43</td>\n",
              "      <td>15115.57</td>\n",
              "      <td>1386.90</td>\n",
              "      <td>91.97</td>\n",
              "      <td>4.559964</td>\n",
              "      <td>4.521027</td>\n",
              "      <td>4.609461</td>\n",
              "      <td>9.623481</td>\n",
              "      <td>7.234826</td>\n",
              "      <td>4.521462</td>\n",
              "      <td>-0.036771</td>\n",
              "      <td>-0.013935</td>\n",
              "      <td>-0.010893</td>\n",
              "      <td>0.018413</td>\n",
              "      <td>-0.063010</td>\n",
              "      <td>-0.016071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-06-28</th>\n",
              "      <td>96.30</td>\n",
              "      <td>96.36</td>\n",
              "      <td>102.49</td>\n",
              "      <td>14909.60</td>\n",
              "      <td>1234.25</td>\n",
              "      <td>96.56</td>\n",
              "      <td>4.567468</td>\n",
              "      <td>4.568091</td>\n",
              "      <td>4.629765</td>\n",
              "      <td>9.609761</td>\n",
              "      <td>7.118219</td>\n",
              "      <td>4.570165</td>\n",
              "      <td>0.007505</td>\n",
              "      <td>0.047064</td>\n",
              "      <td>0.020304</td>\n",
              "      <td>-0.013720</td>\n",
              "      <td>-0.116608</td>\n",
              "      <td>0.048702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-07-31</th>\n",
              "      <td>100.87</td>\n",
              "      <td>105.10</td>\n",
              "      <td>107.89</td>\n",
              "      <td>15499.54</td>\n",
              "      <td>1323.10</td>\n",
              "      <td>105.03</td>\n",
              "      <td>4.613833</td>\n",
              "      <td>4.654912</td>\n",
              "      <td>4.681112</td>\n",
              "      <td>9.648566</td>\n",
              "      <td>7.187733</td>\n",
              "      <td>4.654246</td>\n",
              "      <td>0.046364</td>\n",
              "      <td>0.086821</td>\n",
              "      <td>0.051347</td>\n",
              "      <td>0.038805</td>\n",
              "      <td>0.069514</td>\n",
              "      <td>0.084081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-08-30</th>\n",
              "      <td>102.98</td>\n",
              "      <td>107.98</td>\n",
              "      <td>115.97</td>\n",
              "      <td>14810.31</td>\n",
              "      <td>1396.40</td>\n",
              "      <td>107.65</td>\n",
              "      <td>4.634535</td>\n",
              "      <td>4.681946</td>\n",
              "      <td>4.753332</td>\n",
              "      <td>9.603079</td>\n",
              "      <td>7.241653</td>\n",
              "      <td>4.678885</td>\n",
              "      <td>0.020702</td>\n",
              "      <td>0.027034</td>\n",
              "      <td>0.072219</td>\n",
              "      <td>-0.045487</td>\n",
              "      <td>0.053920</td>\n",
              "      <td>0.024639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-09-30</th>\n",
              "      <td>97.94</td>\n",
              "      <td>102.36</td>\n",
              "      <td>107.85</td>\n",
              "      <td>15129.67</td>\n",
              "      <td>1327.55</td>\n",
              "      <td>102.33</td>\n",
              "      <td>4.584355</td>\n",
              "      <td>4.628496</td>\n",
              "      <td>4.680741</td>\n",
              "      <td>9.624413</td>\n",
              "      <td>7.191090</td>\n",
              "      <td>4.628203</td>\n",
              "      <td>-0.050180</td>\n",
              "      <td>-0.053450</td>\n",
              "      <td>-0.072590</td>\n",
              "      <td>0.021334</td>\n",
              "      <td>-0.050562</td>\n",
              "      <td>-0.050682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>213 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60015ce5-f124-45f8-b4a6-8763f91b8343')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60015ce5-f124-45f8-b4a6-8763f91b8343 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60015ce5-f124-45f8-b4a6-8763f91b8343');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['DiffLogMM'] = df['Log_MM'].diff() #crea una nueva columna con la diferencia del logaritmo \n",
        "df['DiffLogWTI'] = df['Log_WTI'].diff()\n",
        "df['DiffLogBRENT'] = df['Log_Brent'].diff()\n",
        "df['DiffLogDJI'] = df['Log_DJI'].diff()\n",
        "df['DiffLogXAU'] = df['Log_XAU'].diff()\n",
        "df['DiffLogOil C1'] = df['Log_Oil C1'].diff()"
      ],
      "metadata": {
        "id": "V1V3ZQ1K5E1K"
      },
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = df[['DiffLogWTI','DiffLogBRENT','DiffLogDJI', 'DiffLogXAU','DiffLogOil C1']].values\n",
        "targets = df['DiffLogMM'].values"
      ],
      "metadata": {
        "id": "9RnWbvxS_HO_"
      },
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = df[['DiffLogWTI','DiffLogBRENT','DiffLogDJI', 'DiffLogXAU','DiffLogOil C1']].dropna()\n",
        "targets = df['DiffLogMM'].dropna()"
      ],
      "metadata": {
        "id": "MYOqn98cGu-C"
      },
      "execution_count": 485,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_data.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehTRFfdx-hn9",
        "outputId": "153900ab-29e5-4722-8c88-e6eb36269ae6"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(317, 5) (317,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now make the actual data which will go into the neural network\n",
        "T = 12 #the number of time steps to look at to make a prediction for the next day\n",
        "D = input_data.shape[1] #en este ejemplo son 5 porque usamos 5 variables disitntas\n",
        "N = len(input_data) - T # (e.g. if T = 10 and you have 11 data points then you'd onlye have 1 sample )\n",
        "print(T,D,N, len(input_data)*1//3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtYRYuKf58fo",
        "outputId": "9d37429f-4ad6-4a70-f57e-fdb26f7cc821"
      },
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 5 305 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ntest = len(input_data) * 1//3\n",
        "train = df.iloc[:-Ntest] #todos -12\n",
        "test = df.iloc[-Ntest:] #solo las últimas 12 observaciones"
      ],
      "metadata": {
        "id": "Hh9nNJmjLD0U"
      },
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boolean series to index df rows []\n",
        "train_idx = df.index <= train.index[-1] #pone true a lo que sea train del data set y lo demás false\n",
        "test_idx = df.index > train.index[-1] # pone true a lo que sea del test solamente y lo demás false\n",
        "print(train_idx.shape, test_idx.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P87Tr28VLGBa",
        "outputId": "367baa94-c6ed-4a6c-cbb5-cc9ce0a3a831"
      },
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(318,) (318,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_idx,len(input_data) - Ntest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzWNnG_tPYpb",
        "outputId": "ff3eece6-6969-49a5-c969-f2d200fbc7ae"
      },
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False] 212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the inputs\n",
        "Ntrain = len(input_data) * 2//3 - T + 1 #// Ntrain = len(input_data) * 2//3  sin el -T es el orignal\n",
        "print(Ntrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1rQsBtq6FoP",
        "outputId": "0502ff31-70fe-49da-de39-87a7216329de"
      },
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup X_train and Y_train\n",
        "X_train = np.zeros((Ntrain, T, D)) #crea ceros del tensor de 3 dimensiones y la medida son los números de cada definición (1249,5,10)\n",
        "Y_train = np.zeros(Ntrain)\n",
        "\n",
        "for t in range(Ntrain): \n",
        "  X_train[t, :, :] = input_data[t:t+T] #es el recorrido que hacen los datos de 1 en 1 con las 5 variables // X_train[t, :, :] = input_data[t:t+T] \n",
        "  Y_train[t] = (targets[t+T]>0) #booleano, mientras t+T sean > a 0 entonces Y_train será igual a x numero"
      ],
      "metadata": {
        "id": "pIpUXPfiAvtf"
      },
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup X_test and Y_test\n",
        "X_test = np.zeros((N - Ntrain + T, T, D)) #crea ceros del tensor de 3 dimensiones y la medida son los números de cada definición (1249-2/3 Ntrain ,5,10) // original : X_test = np.zeros((N - Ntrain, T, D)) \n",
        "Y_test = np.zeros(N - Ntrain + T) # (1249-839) //original : Y_test = np.zeros(N - Ntrain ) // el original: Y_test = np.zeros(N - Ntrain + T) \n",
        "\n",
        "#Acá llenamos los ceros generados\n",
        "for u in range(N - Ntrain): \n",
        "  # u ocunts from 0... (N - Ntrain)\n",
        "  # t counts form Ntrain...N \n",
        "  t = u + Ntrain #(U toma de 0 hasta N, Ntrain siempre es 839)\n",
        "  X_test[u, :, :] = input_data[t:t+T] #es el recorrido que hacen los datos de 1 en 1 con las 5 variables\n",
        "  Y_test[u] = (targets[t+T]>0) #booleano, mientras t+T sean > a 0 entonces Y_train será igual a x numero"
      ],
      "metadata": {
        "id": "RA7d-gXm6JqB"
      },
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDnatHmAEwsI",
        "outputId": "d9cc0a90-81de-4937-abe4-41aa72b56791"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.09807049  0.12264858  0.01660192 -0.01662157  0.09664167]\n",
            "  [ 0.08977258  0.07824076  0.01833741 -0.01081499  0.09419297]\n",
            "  [-0.02265316 -0.04168316 -0.00323945 -0.00965577 -0.01265543]\n",
            "  ...\n",
            "  [ 0.01916992  0.0160978   0.07849089 -0.01748226  0.01149683]\n",
            "  [ 0.08876792  0.03102012 -0.01132475 -0.00906085  0.09292106]\n",
            "  [-0.06995859 -0.02628384  0.05503397 -0.06656022 -0.07073049]]\n",
            "\n",
            " [[ 0.08977258  0.07824076  0.01833741 -0.01081499  0.09419297]\n",
            "  [-0.02265316 -0.04168316 -0.00323945 -0.00965577 -0.01265543]\n",
            "  [-0.05797301 -0.07450253  0.01321789 -0.00166102 -0.07034149]\n",
            "  ...\n",
            "  [ 0.08876792  0.03102012 -0.01132475 -0.00906085  0.09292106]\n",
            "  [-0.06995859 -0.02628384  0.05503397 -0.06656022 -0.07073049]\n",
            "  [-0.17366349 -0.18026182  0.00944436  0.05343272 -0.17366349]]\n",
            "\n",
            " [[-0.02265316 -0.04168316 -0.00323945 -0.00965577 -0.01265543]\n",
            "  [-0.05797301 -0.07450253  0.01321789 -0.00166102 -0.07034149]\n",
            "  [ 0.05654     0.06315635  0.00202695 -0.0273528   0.05704595]\n",
            "  ...\n",
            "  [-0.06995859 -0.02628384  0.05503397 -0.06656022 -0.07073049]\n",
            "  [-0.17366349 -0.18026182  0.00944436  0.05343272 -0.17366349]\n",
            "  [ 0.00246003 -0.04794176 -0.04372669 -0.03387782  0.00540409]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.03512376  0.11767684  0.00993412  0.00952536  0.03583784]\n",
            "  [ 0.09098659  0.07280573  0.00629592  0.04675516  0.09121368]\n",
            "  [-0.04548889 -0.02281603  0.02610902  0.0462598  -0.04538041]\n",
            "  ...\n",
            "  [-0.04221986 -0.06602712  0.01905876 -0.0794228  -0.03035006]\n",
            "  [-0.01393487 -0.01089335  0.01841258 -0.06300967 -0.0160711 ]\n",
            "  [ 0.04706376  0.02030427 -0.01372004 -0.11660754  0.04870214]]\n",
            "\n",
            " [[ 0.09098659  0.07280573  0.00629592  0.04675516  0.09121368]\n",
            "  [-0.04548889 -0.02281603  0.02610902  0.0462598  -0.04538041]\n",
            "  [-0.06672504 -0.01328833 -0.02567981 -0.02902457 -0.06671756]\n",
            "  ...\n",
            "  [-0.01393487 -0.01089335  0.01841258 -0.06300967 -0.0160711 ]\n",
            "  [ 0.04706376  0.02030427 -0.01372004 -0.11660754  0.04870214]\n",
            "  [ 0.0868211   0.05134696  0.03880505  0.06951397  0.08408145]]\n",
            "\n",
            " [[-0.04548889 -0.02281603  0.02610902  0.0462598  -0.04538041]\n",
            "  [-0.06672504 -0.01328833 -0.02567981 -0.02902457 -0.06671756]\n",
            "  [ 0.02643628  0.00860785 -0.00542685 -0.00334755  0.03049051]\n",
            "  ...\n",
            "  [ 0.04706376  0.02030427 -0.01372004 -0.11660754  0.04870214]\n",
            "  [ 0.0868211   0.05134696  0.03880505  0.06951397  0.08408145]\n",
            "  [ 0.02703375  0.07221935 -0.04548679  0.05392003  0.0246392 ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN \n",
        "i = Input(shape=(T,D))\n",
        "x = LSTM(6)(i)\n",
        "x = Dense(1)(x)\n",
        "model = Model(i,x)"
      ],
      "metadata": {
        "id": "NSLv4E1Z9Umu"
      },
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxscy75sBPsX",
        "outputId": "3e6635fb-0886-4bb0-9dd4-e3f5d876a9be"
      },
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 12, 5)]           0         \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 6)                 288       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 295\n",
            "Trainable params: 295\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer='adam',\n",
        ")"
      ],
      "metadata": {
        "id": "z8CPfNKvBTEJ"
      },
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKWBzOz_BtAH",
        "outputId": "b2434bef-22ee-412a-dfa6-508f0bbb7ef5"
      },
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117, 12, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zcTC9f0ByWE",
        "outputId": "a0881733-6055-4717-8f68-4b95d9f604b7"
      },
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLXqLtEKEeM7",
        "outputId": "3a9073f7-7064-45d7-fd09-7109248d06d0"
      },
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 12, 5) (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hLwfxI6HGMb",
        "outputId": "f8eec480-70e1-45dc-85a2-eb330ebbbcef"
      },
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117, 12, 5) (117,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(X_test,Y_test),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ytEW4gyBWDW",
        "outputId": "01fac820-d6bf-437c-b119-2439fb796c6f"
      },
      "execution_count": 513,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 3s 94ms/step - loss: 0.5671 - val_loss: 0.5241\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5482 - val_loss: 0.5067\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5294 - val_loss: 0.4886\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5099 - val_loss: 0.4691\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4885 - val_loss: 0.4474\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4642 - val_loss: 0.4231\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4362 - val_loss: 0.3958\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4044 - val_loss: 0.3653\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3716 - val_loss: 0.3315\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3320 - val_loss: 0.2980\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2948 - val_loss: 0.2696\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2668 - val_loss: 0.2532\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2490 - val_loss: 0.2507\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2451 - val_loss: 0.2525\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2465 - val_loss: 0.2547\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2468 - val_loss: 0.2537\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2460 - val_loss: 0.2517\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2463 - val_loss: 0.2505\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2460 - val_loss: 0.2501\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2458 - val_loss: 0.2501\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2459 - val_loss: 0.2502\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2456 - val_loss: 0.2499\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2457 - val_loss: 0.2499\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2457 - val_loss: 0.2509\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2460 - val_loss: 0.2514\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2452 - val_loss: 0.2503\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2456 - val_loss: 0.2498\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2452 - val_loss: 0.2496\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2453 - val_loss: 0.2497\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2452 - val_loss: 0.2495\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2451 - val_loss: 0.2493\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2453 - val_loss: 0.2494\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2462 - val_loss: 0.2488\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2456 - val_loss: 0.2488\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2453 - val_loss: 0.2489\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2451 - val_loss: 0.2490\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2451 - val_loss: 0.2492\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2449 - val_loss: 0.2496\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2448 - val_loss: 0.2496\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2447 - val_loss: 0.2489\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2449 - val_loss: 0.2489\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2448 - val_loss: 0.2487\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2448 - val_loss: 0.2486\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2455 - val_loss: 0.2482\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2451 - val_loss: 0.2484\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2451 - val_loss: 0.2491\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2446 - val_loss: 0.2485\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2445 - val_loss: 0.2484\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2446 - val_loss: 0.2483\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2450 - val_loss: 0.2485\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2444 - val_loss: 0.2481\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2446 - val_loss: 0.2482\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2441 - val_loss: 0.2486\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2440 - val_loss: 0.2494\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2443 - val_loss: 0.2500\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2445 - val_loss: 0.2502\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2446 - val_loss: 0.2502\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2443 - val_loss: 0.2488\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2441 - val_loss: 0.2482\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.2483\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2443 - val_loss: 0.2475\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2440 - val_loss: 0.2474\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2441 - val_loss: 0.2472\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2442 - val_loss: 0.2472\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2443 - val_loss: 0.2483\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2438 - val_loss: 0.2485\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2440 - val_loss: 0.2483\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2438 - val_loss: 0.2486\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2438 - val_loss: 0.2481\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2440 - val_loss: 0.2474\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2442 - val_loss: 0.2469\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2437 - val_loss: 0.2474\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2437 - val_loss: 0.2477\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2436 - val_loss: 0.2471\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2434 - val_loss: 0.2467\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2435 - val_loss: 0.2462\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2437 - val_loss: 0.2461\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2433 - val_loss: 0.2464\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2432 - val_loss: 0.2473\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2437 - val_loss: 0.2491\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2444 - val_loss: 0.2475\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2435 - val_loss: 0.2478\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2438 - val_loss: 0.2485\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2434 - val_loss: 0.2473\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2432 - val_loss: 0.2466\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2430 - val_loss: 0.2461\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2430 - val_loss: 0.2462\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2430 - val_loss: 0.2464\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2428 - val_loss: 0.2455\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2432 - val_loss: 0.2452\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2435 - val_loss: 0.2452\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2430 - val_loss: 0.2455\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2433 - val_loss: 0.2455\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2430 - val_loss: 0.2466\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2427 - val_loss: 0.2466\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2426 - val_loss: 0.2469\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2429 - val_loss: 0.2461\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2425 - val_loss: 0.2458\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2426 - val_loss: 0.2456\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2425 - val_loss: 0.2447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(r.history['loss'],label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='test loss')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xsbtNl4gHMma",
        "outputId": "b7e15073-056a-4302-c9fb-95e721aba46c"
      },
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx[:T+1] = False # First T+1 values are not predictable"
      ],
      "metadata": {
        "id": "RM_Ojfi2HOJa"
      },
      "execution_count": 515,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_idx[:T+1]) #Me imprime lo que tenemos False en el entrenamiento "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVk2H5juHQvs",
        "outputId": "11d20326-9c80-463b-91ca-cd92056384f1"
      },
      "execution_count": 516,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ptrain = model.predict(X_train).flatten()\n",
        "Ptest = model.predict(X_test).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBymf8o3HT6k",
        "outputId": "f124b8a4-7c03-4a9e-a684-c0215bcd416b"
      },
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Ptrain.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zuOGHZXHre1",
        "outputId": "3596433d-05b6-4d9d-efbe-b32f762f1618"
      },
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Ptest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH2XJ_PFHWX2",
        "outputId": "1e6edb28-597f-47e0-f81f-3892593e98b3"
      },
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XogAQAbgHxqI",
        "outputId": "7426ccab-a1f0-4116-a538-545da080befd"
      },
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(317, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "199+118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyXVmbrzIDTs",
        "outputId": "afe6a6ad-3397-4671-ca23-c6fbd68269cb"
      },
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "317"
            ]
          },
          "metadata": {},
          "execution_count": 521
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Needed to compute un-differenced predictions\n",
        "df['ShiftLogMM'] = df['Log_MM'].shift(1) #cambia 1 periodo hacia adelante los datos\n",
        "prev = df['ShiftLogMM']\n",
        "ValuesView(prev.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNICwVGiIHda",
        "outputId": "5593b620-903b-41bd-da13-4d6480707015"
      },
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ValuesView(Fecha\n",
              "2022-02-28    4.420165\n",
              "2022-03-31    4.519612\n",
              "2022-04-29    4.584967\n",
              "2022-05-31    4.625169\n",
              "2022-06-30    4.734706\n",
              "Name: ShiftLogMM, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 522
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Ptrain.shape, prev[train_idx].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViFNaKMmIV1v",
        "outputId": "8c4e18a2-356f-4556-f05c-e78c4cde99e6"
      },
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,) (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Last-known train value\n",
        "last_train = train.iloc[-1]['Log_MM']"
      ],
      "metadata": {
        "id": "e2ZzB32bIerL"
      },
      "execution_count": 524,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ValuesView(last_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEa46A01IhS2",
        "outputId": "a5ed8d59-1a7a-419f-94a6-0a4f27eba19a"
      },
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ValuesView(4.584355046274172)"
            ]
          },
          "metadata": {},
          "execution_count": 525
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-step forecast[]\n",
        "df.loc[train_idx, '1step_train'] = prev[train_idx] + Ptrain #Te regresa las 121 observaciones con true //con el loc me regresa del df algo en específico //prev[train_idx] =121 lenght + 121 lenght ptrain\n",
        "df.loc[test_idx, '1step_test'] = prev[test_idx] + Ptest #Te regresa las 12 observaciones con true // prev[test_idx] 12 lenght + ptest 12 lenght"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "INV4yhtgIf89",
        "outputId": "72f0d72e-aa77-485b-d7b7-4c09a52b6a4c"
      },
      "execution_count": 526,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-526-e41335756156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1-step forecast[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1step_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPtrain\u001b[0m \u001b[0;31m#Te regresa las 121 observaciones con true //con el loc me regresa del df algo en específico //prev[train_idx] =121 lenght + 121 lenght ptrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1step_test'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPtest\u001b[0m \u001b[0;31m#Te regresa las 12 observaciones con true // prev[test_idx] 12 lenght + ptest 12 lenght\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__add__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__radd__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5526\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5528\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (105,) (117,) "
          ]
        }
      ]
    }
  ]
}